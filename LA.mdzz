Problems and theorems in linear algebra

Techniques
(general)
T1.mathematical induction
T2.pretend variable as constant
T3.substitute and compute
T8.uniqueness, independence etc. argument
T9.evaluation
T15.factorize the polynomial
T17.Recast messy lines
T18.Construct morphisms
T22.intermediate value theorem
T23.compactness implies "finiteness"
(complex analytic)
T16.use Liouville to prove constant
T20.vanishes on R implies vanishes on C
(specific)
T4.view the left action by a matrix as row operation
T5.work on the level of block
T6.decomposition into products (maybe by guesswork)
T7.Cauchy-Binet
T10.dimension counting
T11. work at the level of linear maps instead of matrices
T12. rank standard form
T13. Jordan techniques
T14.localize to an invariant subspace
T19.Inner product viewpoint and duality
T21.other canonical forms
T24.Schur's unitary triangulation
T25.canonical forms under the transformation W*AW (W invertible) is the signatures
T26.consider AA*
T27.consider P=S^2
T28.the cayley transformation
 
1.1 (Cramer rule) 
P1.do T1. the base step is trivial, for the induction step, use T2.
P2.do T3 to rhs.

1.7 (generalization of row operation)
P1.use T4.
P2.use T5 combined with T6.

2.2
P1.immediate by contradiction.
P2.compute to construct an explicit linear relationship.

2.3 (Cauchy-Binet)
This result does not admit a simpler proof (and since the proof uses linearity heavily, which is the core as well as basic stuff of LA) so itself will be added to the list of tools.
We prove this for the smallest non-trivial case.
the proof is at Cauchy-Binet.jpg.

2.5.1 (Jacobi)
P1.use generalized laplace expansion (2.4.1) (k-minor) to get an expression (i). apply T7 to the standard equation A*adj(A)=det(A)*I (first k row of A and first k column of adj(A)) to get an expression (ii). conclude by T8 wrt. (i)&(ii).
P2.use T5 combined with T9.

3.2(Haynsworth quotient)
P1. T3 brute force (by definition formula of Schur complement and formula for inverse matrix)
P2. T6
6.1 (dimension counting of im intersection with kernel)
P. T10

6.3.2 (rank standard form)
P1. T4
P2. T11

6.3.3 (solvability of C=AXB)
P. apply T12 to A and B.

7.3 (Aupetit)
P1.transform the problem into another: existence of commutators satisfying some relationship. split the problem into two parts, analysis of rank of commutator operator and find enough independent vectors. the second one is easy. To carry out an analysis of rank of the operator, use T13).
P2.this proof is better since it is true for infinite dimensional. use T14 (not important here), T15 (important because here factorize into eigenvalues), T16(vital)

8.3 (Flanders)
P2.use T12,T5,T17 to derive relationships. to enforce T10, use T18 and T19.

12.1
P1.carry out a laborious detailed analysis
P2.use T20

15.2
P1.use T22 followed by an averaging process.
P2.use T22 followed by T23

16.2.2
P1. reduce U1 and U2. equivalent to prove sqrt(AA*)=Asqrt(A*A)A^-1,note that AA*=AA*AA^-1, use T8
P2. directly write down the decompositions using svd decomposition, use T8

23.1.2 (the backward direction)
P1. use relationship between commute matrix and their eigenvectors
P2. use the characterization of normality to construct
